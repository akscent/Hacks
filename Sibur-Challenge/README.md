<img src="https://raw.githubusercontent.com/akscent/Hacks/main/Sibur-Challenge/img/banner.png">

# Описание задачи
Были заданы параметры какой-то газовоздушной смеси вместе с 4 таргетами. Было 2 типа газа. Нужно было численно предсказать таргеты. То есть это была классическая задача табличного ml. Загвостка заключалась в том, что распределения данных умышленно были обрезаны, а в тестовом датасете могли содержаться наблюдения, не присутствующие ни в тренировочном, ни в валидационном.


**Полезная информация**

Был предоставлен [BaseLine](https://github.com/akscent/Hacks/blob/main/Sibur-Challenge/notebooks/Baseline.ipynb) с простым `catboost` решением. 

Для загрузки решения нужно было загрузить архив ([соержимое папки src](https://github.com/akscent/Hacks/tree/main/Sibur-Challenge/src)) c doker-файлом и функцией `predict.py`.

# Решение

Исследовательский [ноутбук](https://github.com/akscent/Hacks/blob/main/Sibur-Challenge/notebooks/sibur-lstm-catboost-lgbm.ipynb) показывает, что целесообразно было разбить таргеты на 4 группы по таргет-гез. Кроме того, в данных прослеживается полиноминальныя зависимость.

Тем не менее было решено использовать lstm модель для предсказания, ввиду ограниченного количества ресурсов и времени.

# Результат
В итоге получилась не плохая модель, примерно так показывающая себя на валидационных данных:

<img src="https://raw.githubusercontent.com/akscent/Hacks/main/Sibur-Challenge/img/graph.png">

Тем не менее на тренировочных данных решение было далеко от идеального, и все-таки решение с полиноминальной регрессией было куда более эффективным.
